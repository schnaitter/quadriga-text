{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d59fe07",
   "metadata": {},
   "source": [
    "# Data Input and Homogenisation\n",
    "\n",
    "## 1. Types of input data for text corpora\n",
    "\n",
    "Textual data might come in different forms. \n",
    "\n",
    "1. It could be **plain text**:\n",
    "\n",
    "```\n",
    "Die Grippe wütet weiter\n",
    "Zunahme der schweren Fälle in Berlin. Die Zahl der Grippefälle ist in den letzten beiden Tagen auch in Groß-Berlin noch deutlich gestiegen. Die Warenhäuser und sonstigen Geschäfte, die Kriegs- und die privaten Betriebe klagen, dass übermäßig viele Angestellte krank melden müssen, und auch bei der Post und bei der Straßenbahn ist die Zahl der Grippekranken bedeutend gestiegen.\n",
    "```\n",
    "\n",
    "2. It could be **images** (pdf, jpg, etc):\n",
    "\n",
    "<img src=\"grippe1.png\" width=700>\n",
    "\n",
    "(source: Berliner Morgenpost, October 15, 1918)\n",
    "\n",
    "3. It could be some **structured markup** (XML/HTML):\n",
    "\n",
    "```\n",
    "<text>\n",
    "    <head>\n",
    "        Die Grippe wütet weiter\n",
    "    </head>\n",
    "    <p>\n",
    "        <s>Zunahme der schweren Fälle in Berlin.</s> \n",
    "        <s>Die Zahl der Grippefälle ist in den letzten beiden Tagen auch in Groß-Berlin noch deutlich gestiegen.</s>\n",
    "        <s>Die Warenhäuser und sonstigen Geschäfte, die Kriegs- und die privaten Betriebe klagen, dass übermäßig viele Angestellte krank melden müssen, und auch bei der Post und bei der Straßenbahn ist die Zahl der Grippekranken bedeutend gestiegen.</s>\n",
    "    </p>\n",
    "</text>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aaad4b",
   "metadata": {},
   "source": [
    "#### We have to be able to use all these formats and homogenise different sources into a unified corpus. \n",
    "\n",
    "In most cases, working with plain text is the simplest option (though sometimes you might actually want to *keep* structured XML/HTML markup and rely on that structure in your analysis). So we will convert everything to plain text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ff2e7",
   "metadata": {},
   "source": [
    "<img src=\"homogenisationchart.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29466219",
   "metadata": {},
   "source": [
    "## 2.  images into digial text. OCR\n",
    "\n",
    "To process images into digital text we need an **Optical Character Recognition (OCR)** tool. \n",
    "\n",
    "![](grippeocr.gif)\n",
    "\n",
    "### How OCR works\n",
    "\n",
    "A modern Optical Character Recognition (OCR) algorithm typically involves several stages. Here’s a breakdown of the key stages:\n",
    "\n",
    "1. **Preprocessing**: This initial step involves preparing the image for analysis and recognition. Common preprocessing tasks include:\n",
    "   - **Noise Reduction**: Removing noise from the image to enhance the text's clarity. This could involve filtering techniques like Gaussian blur or median filter.\n",
    "   - **Binarization**: Converting the image from grayscale or color to black-and-white, where text is typically represented as black pixels on a white background. This helps in distinguishing the text from the background.\n",
    "   - **Normalization**: Standardizing the brightness and contrast of the image to reduce variability between different images.\n",
    "   - **Dewarping**: Correcting any image distortions that result from curved surfaces or skewed scanning angles.\n",
    "\n",
    "2. **Segmentation**: This step divides the image into parts that are easier to analyze. Segmentation levels can vary based on the complexity of the layout and the requirements of the application:\n",
    "   - **Page Segmentation**: Identifying different blocks of text, images, or other elements on a page.\n",
    "   - **Line Segmentation**: Breaking down text blocks into individual lines.\n",
    "   - **Word Segmentation**: Further dividing lines into words.\n",
    "   - **Character Segmentation**: The final step where words are broken down into individual characters.\n",
    "\n",
    "3. **Feature Extraction**: In this stage, the algorithm extracts features from the segmented characters that are useful for recognition. This might include the basic shape, line endpoints, intersections, and other geometrical and topological characteristics.\n",
    "\n",
    "4. **Character Recognition**: At this stage, each character image is analyzed and compared against a pre-trained model to identify the most likely corresponding textual character. Techniques used in this stage can vary:\n",
    "   - **Pattern Recognition**: Using methods such as support vector machines or neural networks to recognize characters based on the features extracted.\n",
    "   - **Template Matching**: Comparing character images to a set of predefined character templates to find the best match.\n",
    "\n",
    "5. **Post-processing**: After characters are recognized, the algorithm performs corrections based on context and additional information:\n",
    "   - **Spell Checking and Correction**: Identifying and correcting misspelled words using dictionaries and context-based algorithms.\n",
    "   - **Language and Grammar Analysis**: Applying language-specific rules to improve the accuracy of the output text.\n",
    "\n",
    "6. **Output Formatting**: The final text is formatted according to the desired output specifications, which may include maintaining the layout, fonts, and style of the original text.\n",
    "\n",
    "Each of these stages can be enhanced by deep learning techniques, especially convolutional neural networks (CNNs) and recurrent neural networks (RNNs), which can learn to handle many of the tasks automatically and often provide better accuracy than traditional methods, especially in complex or noisy environments.\n",
    "\n",
    "\n",
    "### What OCR tools are there\n",
    "\n",
    "The field of making OCR tools is developing rapidly (together with all other fields of text processing), so there are always new tools challenging the old ones. But as of 2024, the well-known products were: \n",
    "\n",
    "* FineReader (commercial, has a desktop interface)\n",
    "* Tesseract (open source, command-line interface)\n",
    "* OCR4all (open source, has a (dockerized locally deployable) desktop interface)\n",
    "* Kraken & e-Scriptorium (open source, e-Scriptorium has a desktop interface)\n",
    "* EasyOCR (open source, has a desktop interface)\n",
    "\n",
    "We'll use Tesseract in this tutorial, which is an open & free tool. Specifically, we'll use the Python package PyTesseract. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3af423bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pytesseract\n",
    "#!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a636708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "273defc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9efa76",
   "metadata": {},
   "source": [
    "### 2.1. Evaluate OCR engine quality\n",
    "\n",
    "Before processing all files, we evaluate OCR quality on a sample image part for evaluation(source: [Deutsche Zeitung, Ausgaben am Montag, 23.12.1918](https://zefys.staatsbibliothek-berlin.de/kalender/auswahl/date/1918-12-23/30744015/)):\n",
    "![sample.jpg](sample.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d817e",
   "metadata": {},
   "source": [
    "Let us OCR it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84c9fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_output = pytesseract.image_to_string(Image.open('sample.jpg'), lang='frk')  # using German fraktur OCR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5ca0449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Lage anfdemKohlenmarkte gibt zu “en ſhlimm-\n",
      "ſten Befürc<tungen Anlaß. Für Sachſen fehlten im Nov»mber\n",
      "30 000 Wagen zu je 10 Tonnen und für Tezembex wird mit no<\n",
      "größeren Ausfällen gere<net werden. E3 iſt mit einem völligen\n",
      "Stillſtand der Induſtrie innerhalb vierzehn Tagen zu red<hnen,\n",
      "wenn nicht eine erhebliche Steigerung der Belenſ<aften der Kot:en-\n",
      "bergwerke oder ihrer Zah! geiingt. Weiter ſteht eine weſentliche\n",
      "Erhöhung der Kohlenpreije bevor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ocr_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1328b4ad",
   "metadata": {},
   "source": [
    "#### 2.1.1 Manually create  the 'ground truth' to evaluate against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55a68c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please insert corrected string: Die Lage an dem Kohlenmarkte gibt zu den ſhlimmſten Befürchtungen Anlaß. Für Sachſen fehlten im November 30 000 Wagen zu je 10 Tonnen und für Dezember wird mit noch größeren Ausfällen gerechnet werden. Eſ iſt mit einem völligen Stillſtand der Induſtrie innerhalb vierzehn Tagen zu rechhnen, wenn nicht eine erhebliche Steigerung der Belenſchaften der Kohlenbergwerke oder ihrer Zahl gelingt. Weiter ſteht eine weſentliche Erhöhung der Kohlenpreiſe bevor.\n"
     ]
    }
   ],
   "source": [
    "ground_truth = input('Please insert corrected string: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c35c218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Lage an dem Kohlenmarkte gibt zu den ſhlimmſten Befürchtungen Anlaß. Für Sachſen fehlten im November 30 000 Wagen zu je 10 Tonnen und für Dezember wird mit noch größeren Ausfällen gerechnet werden. Eſ iſt mit einem völligen Stillſtand der Induſtrie innerhalb vierzehn Tagen zu rechhnen, wenn nicht eine erhebliche Steigerung der Belenſchaften der Kohlenbergwerke oder ihrer Zahl gelingt. Weiter ſteht eine weſentliche Erhöhung der Kohlenpreiſe bevor.\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc90f22d",
   "metadata": {},
   "source": [
    "#### 2.1.2 Measure OCR precision, recall and F-measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480c66de",
   "metadata": {},
   "source": [
    "In the context of Optical Character Recognition (OCR), precision, recall, and F-measure are metrics used to evaluate the accuracy and efficiency of OCR systems in converting images of typed, handwritten, or printed text into machine-encoded text. These metrics help to understand how well an OCR system performs, especially in terms of correctly identifying characters, words, or specific information within documents. Here's how these metrics apply to OCR quality evaluation:\n",
    "\n",
    "###### Precision in OCR\n",
    "In OCR, precision measures the accuracy of the recognized text against the actual text in the document images. It calculates the proportion of correctly identified characters or words out of all the characters or words that the OCR system identified. High precision means that most of the text the OCR system identified as present in the document was actually correct, indicating fewer false positives (i.e., incorrectly identified as present).\n",
    "\n",
    "![](precision.png)\n",
    "\n",
    "##### Recall in OCR\n",
    "Recall in the context of OCR measures the OCR system's ability to capture all the relevant characters or words from the document images. It is the ratio of the correctly identified characters or words to all the characters or words that are actually present in the documents. High recall indicates that the OCR system is able to identify most of the actual text present, minimizing false negatives (i.e., failing to recognize text that is there).\n",
    "\n",
    "![](recall.png)\n",
    "\n",
    "##### F-measure (F1 Score) in OCR\n",
    "The F-measure or F1 score in OCR provides a single metric that combines both precision and recall to give a balanced view of the OCR system's overall performance. Since precision and recall have a trade-off (improving one can often lead to a reduction in the other), the F1 score helps to evaluate the OCR system's effectiveness at recognizing text accurately while minimizing both false positives and false negatives.\n",
    "\n",
    "![](fmeasure.png)\n",
    "\n",
    "These metrics are critical for assessing OCR systems, particularly in applications where the accuracy of text recognition directly impacts the outcome, such as document automation, data extraction from scanned documents, and automated processing of handwritten forms. A balance between high precision and high recall is often desired to ensure that the OCR system is both accurate and comprehensive in its text recognition capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "064eddee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein as lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b306d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_quality(ocr_output, ground_truth):\n",
    "    \"\"\"\n",
    "    Calculates precision, recall, and F1-score\n",
    "    using the Levenshtein distance to align text from OCR with the ground truth data.\n",
    "\n",
    "    :param ocr_output: A string containing the raw OCR results.\n",
    "    :param ground_truth: A string containing the verified ground truth text.\n",
    "    \"\"\"\n",
    "\n",
    "    matching_parts = lev.matching_blocks(lev.editops(ocr_output, ground_truth), ocr_output, ground_truth)\n",
    "    true_pos = len(''.join([ocr_output[x[0]:x[0]+x[2]] for x in matching_parts]))\n",
    "\n",
    "    precision = true_pos / len(ground_truth)\n",
    "    recall = true_pos / len(ocr_output)\n",
    "    f_score = 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "    return precision, recall, f_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03132c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f_score = measure_quality(ocr_output, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46857ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9427\n",
      "Recall: 0.9407\n",
      "F1-score: 0.9417\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision: {round(precision, 4)}\\nRecall: {round(recall, 4)}\\nF1-score: {round(f_score, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c60c71",
   "metadata": {},
   "source": [
    "### 2.2 Process the whole corpus of PDF-s with the same OCR engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74682bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91568303",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathpdf = '../data/pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a69f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in tqdm(os.listdir(pathpdf)):\n",
    "    if '.pdf' in filename:\n",
    "        thispath = os.path.join(pathpdf, filename)\n",
    "        converted_pdf = convert_from_path(thispath, use_cropbox=True)\n",
    "        with open(thispath.replace('.pdf', '.txt'), 'w') as output_txt:\n",
    "            for image in converted_pdf:\n",
    "                recognized = pytesseract.image_to_string(image, \n",
    "                                                         lang='frk') \n",
    "                output_txt.write(recognized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c652166",
   "metadata": {},
   "source": [
    "#### After running this we have all our PDF-s in plain txt form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e74402",
   "metadata": {},
   "source": [
    "### 2.3. OCR postprocessing\n",
    "\n",
    "As we mentioned before, the last stage of the OCR process is post-processing the result. Some of it is done internally by the OCR engine. Other improvement can be applied separately afterwards. \n",
    "\n",
    "#### 2.3.1. Rule-based OCR postprocessing\n",
    "\n",
    "After doing OCR, one can often notice regular errors , e.g. letter `с` turning to `<` or letter `l` becoming a `!`. In many cases we can fix it with some regular search-and replace patterns (e.g. take each `<` not surrounded by spaces and convert into `c`)\n",
    "\n",
    "The standard way to express & implement such patterns on a computer would be regular expressions. For example, here is a regular expression that does the aforementioned context-aware transformation of `<` to `c`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc13fd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50364dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Die Lage anfdemKohlenmarkte gibt zu “en ſhlimm-\\nſten Befürc<tungen Anlaß. Für Sachſen fehlten im Nov»mber\\n30 000 Wagen zu je 10 Tonnen und für Tezembex wird mit no<\\ngrößeren Ausfällen gere<net werden. E3 iſt mit einem völligen\\nStillſtand der Induſtrie innerhalb vierzehn Tagen zu red<hnen,\\nwenn nicht eine erhebliche Steigerung der Belenſ<aften der Kot:en-\\nbergwerke oder ihrer Zah! geiingt. Weiter ſteht eine weſentliche\\nErhöhung der Kohlenpreije bevor.\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31d6e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_output_corr = re.sub('(\\w)<(\\w)', '\\\\1c\\\\2', ocr_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb1b96",
   "metadata": {},
   "source": [
    "Let us see how the whole thing changed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d6c8869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Die Lage anfdemKohlenmarkte gibt zu “en ſhlimm-\\nſten Befürcctungen Anlaß. Für Sachſen fehlten im Nov»mber\\n30 000 Wagen zu je 10 Tonnen und für Tezembex wird mit no<\\ngrößeren Ausfällen gerecnet werden. E3 iſt mit einem völligen\\nStillſtand der Induſtrie innerhalb vierzehn Tagen zu redchnen,\\nwenn nicht eine erhebliche Steigerung der Belenſcaften der Kot:en-\\nbergwerke oder ihrer Zah! geiingt. Weiter ſteht eine weſentliche\\nErhöhung der Kohlenpreije bevor.\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_output_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e61377",
   "metadata": {},
   "source": [
    "So, the '<' is gone now in most cases (but not in all, since we have an additional condition in place). You can learn more about regular expressions [here](https://www.w3schools.com/python/python_regex.asp)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e9bc5b",
   "metadata": {},
   "source": [
    "Let us see hot that affected the OCR quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cffb4d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f_score = measure_quality(ocr_output_corr, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c82ec01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9493\n",
      "Recall: 0.9473\n",
      "F1-score: 0.9483\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision: {round(precision, 4)}\\nRecall: {round(recall, 4)}\\nF1-score: {round(f_score, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd8ed46",
   "metadata": {},
   "source": [
    "So, our F-measure increased a bit, good!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4b8f55",
   "metadata": {},
   "source": [
    "#### 2.3.2. OCR postprocessing with large language models (LLMs)\n",
    "\n",
    "* Here we intend to use Llama3, which is quite good for OCR postcorrection of the german text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae4d69d",
   "metadata": {},
   "source": [
    "## 3.  Getting digial text from the structured markup (XML)\n",
    "\n",
    "Unlike text on the image, XML/HTML are already machine readable, so they are a lower-hanging fruit. Still, we'll need to use a parser for such markup to get rid of XML/HTML tags and some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df1538a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d1237d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathtoxmlfiles = '../data/xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272de86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(pathtoxmlfiles):\n",
    "    if '.xml' in filename:\n",
    "        path2file = os.path.join(pathtoxmlfiles, filename)\n",
    "        with open(path2file) as openxml:\n",
    "            soup = BeautifulSoup(openxml)\n",
    "        print(soup.find('text').text.strip())\n",
    "        #with open(path2file.replace('.txt', '.xml'), 'w') as output_xml:\n",
    "        #    output.write(soup.find('text').text.strip())\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43785012",
   "metadata": {},
   "source": [
    "#### After running this we have all our XML-s in plain txt form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f888d4",
   "metadata": {},
   "source": [
    "## Now let's use all the data for processing and analysis (next notebook)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
